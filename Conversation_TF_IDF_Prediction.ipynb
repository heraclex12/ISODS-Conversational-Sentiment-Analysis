{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conversation TF-IDF - Prediction",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VN1KXa47k20ukOssQ_eMm_1tjq-aQRK-",
      "authorship_tag": "ABX9TyP4nY709mspEDSoW345lo3z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heraclex12/ISODS-Conversational-Sentiment-Analysis/blob/main/Conversation_TF_IDF_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD3_37NVgLUP",
        "outputId": "bb2514c3-a9d3-4da4-dc46-f924c7562177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install vncorenlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vncorenlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=699081ad7a1f8801c4babb13f66c97858b5e0e60f3464472870d27e20df9f8cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jyC0HY3gRCs"
      },
      "source": [
        "import os\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from vncorenlp import VnCoreNLP\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pickle\n",
        "import scipy.sparse\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf1GOMhfizO-"
      },
      "source": [
        "filename = 'test.csv'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaaUHZSNgpG1"
      },
      "source": [
        "df_test = pd.read_csv(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zkZol16gtsB"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "data_test_q = df_test.question.apply(lambda s: re.sub('[' + string.punctuation + ']', ' ', s)).values\n",
        "data_test_a = df_test.answer.apply(lambda s: re.sub('[' + string.punctuation + ']', ' ', s)).values\n",
        "\n",
        "def transform_text(X):\n",
        "    conversations = [\". \".join(messages.lower().split('|||')) for messages in X]\n",
        "    conversations = [\" \".join(\" \".join(sentence) for sentence in tokenizer.tokenize(message)) for message in conversations]\n",
        "    return conversations\n",
        "\n",
        "tokenizer = VnCoreNLP('VnCoreNLP-1.1.1.jar', annotators='wseg')\n",
        "data_test_q = transform_text(data_test_q)\n",
        "data_test_a = transform_text(data_test_a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdPU0KNhg53a"
      },
      "source": [
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "vectorize_a = pickle.load(open('vectorize_a.pkl', 'rb'))\n",
        "vectorize_q = pickle.load(open('vectorize_q.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWNwrJLNg0Rc"
      },
      "source": [
        "test_vector_q = vectorize_q.transform(data_test_q)\n",
        "test_vector_a = vectorize_a.transform(data_test_a)\n",
        "\n",
        "test_vector = scipy.sparse.hstack([test_vector_q, test_vector_a])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziqlLJCMhVpB"
      },
      "source": [
        "preds = model.predict_proba(test_vector)[:, 1]\n",
        "preds\n",
        "with open('submission.csv', 'w') as csv_file:\n",
        "  writer = csv.writer(csv_file)\n",
        "  writer.writerow(['num', 'label'])\n",
        "  pred_label = 1*(preds>=0.8)\n",
        "  for i, label in enumerate(pred_label):\n",
        "    writer.writerow([i + 1, 'Y' if label == 1 else 'N'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ela94BCiPRz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}